<!--

Agentware - The Coming Revolution Automating the Future of Work and Society 

-->

# Introduction

<br />

> *"Agents are not only going to change how everyone interacts with computers.
    They’re also going to upend the software industry, bringing about the biggest revolution in computing since we went from typing commands to tapping on icons."*
> 
> <a href="https://www.gatesnotes.com/AI-agents">THE FUTURE OF AGENTS (AI is about to completely change how you use computers, And upend the software industry.)</a>
> 
> Bill Gates, November 9, 2023. 

<br />

<!-- -->
Note: The AI Industry is moving at lightning speed. This introduction was updated as at November 23, 2023.
<!-- -->

This recent quote from Microsoft Founder Bill Gates is particularly timely, because he has written about artificial intelligence (AI), digital agents or digital assistants for over three decades.

In another instance, Gates recounts his first encounters with GPT at OpenAI before it became ChatGPT, the way we know it now.  He had a privileged view behind the curtain before most of us and he was himself surprised by the speed of progress in 2022:

> In mid-2022, I was so excited about their work that I gave them a challenge: train an artificial intelligence to pass an Advanced Placement biology exam. Make it capable of answering questions that it hasn’t been specifically trained for. (I picked AP Bio because the test is more than a simple regurgitation of scientific facts — it asks you to think critically about biology.) If you can do that, I said, then you’ll have made a true breakthrough. I thought the challenge would keep them busy for two or three years. They finished it in just a few months."

We know that, as humans, we have a hard time understanding how quickly exponential technology can advance. We inevitably underestimate the impact of exponential technology such as AI.

The flood gates have opened. What we're witnessing is progress in artifical intellignce that arrived "gradually, then all at once."

To understand our context, and the context for this book about the future with ubiquitous AI, let's look at the state of the AI industry.

## State of the AI Industry
2023 started off with a bang.

OpenAI's ChatGPT became the fastest growing online product to launch in the short history of the internet. 

ChatGPT literally brought the world's intelligence to our fingertips for $20/month.

ChatGPT was the catalyst to a reimagining of the internet.  No less than the future of "Search" was at stake.

ChatGPT-3 was the spark that brought tens of thousands of generative AI startups to life, revitalizing San Francisco and Silcon Valley, after recouperating from a long crypto winter.

Hundreds of events and hackathons in the Valley alone resulted in billions of dollars of investments into the AI space.

Geoffrey Hinton left his role at Google so that he could warn the world of impending doom.  Fee-Fei Li, of Stanford struck a similar tone to Hinton at a Radical Ventures in Toronto in October 2023.   

Geoffrey Hinton and Yoshua Benjio came to be on the opposite side of their Turing Award co-winner Yann LeCun and Andrew Ng when it came to the topic of open sourcing the LLMs. 

Elon Musk revealed that OpenAI was initially envisioned as open source technology and he disagreed with Larry Page of Google about sharing it with the world.

OpenAI subsequently became a close source company with significant investment capital from Microsoft.

### The Infamous "Pause" Letter
In March of 2023, around the launch of GPT-4, researchers and innovators across the globe signed the letter entitled "Pause Giant AI Experiements: An Open Letter".  Many believed we wer in "Oppenheimer" territory, on the verge of unleashing a technological shock wave on the human race. 
    https://futureoflife.org/open-letter/pause-giant-ai-experiments/


In April 2023, a leaked internal Google memo written by Luke Sernau, a senior software engineer at Google, stirred significant discussion within the tech community. The memo, titled "We Have No Moat," declared that both Google and OpenAI do not have a competitive advantage ("no moat") in the field of generative AI compared to open-source alternatives. The memo emphasized that while companies like Google and OpenAI have been focused on each other, open-source projects have been rapidly solving major AI problems more efficiently and at a faster pace.

Throughout 2023, all of the major platforms and the big name consultancies dove into the deep end with billions of dollards of commitments. 

- McKinsey partnered with Cohere and launched Lilli.
- EY committed and pivoted their entre firm to EY.ai
- PwC committed to The New Equation, initiating training in Generative AI for it's entire workforce
- KPMG created Generative AI offerings
- Deloitte created a Centre of Excellence. 
(additional statements)
- Billionaire investor, a16z founder, Marc Andreesen penned "Why AI Will Save the World" in June 2023.
    https://a16z.com/ai-will-save-the-world/
- Andreesen published his widely-discussed "Techno-Optomist Manifesto" in October 2023.
    https://a16z.com/the-techno-optimist-manifesto/

At the time of this writing in November 2023, the AI landscape has witnessed the explosive growth of generative AI ("GenAI") tools, following what seems to be continuous launches of OpenAI's ChatGPT Large Language Models, their evolving chat interfaces in both web and native apps and new feature sets.

The GenAI market is inevitably set for immense growth, with most forecasts for the 2030 market are in the US $75 billion to $130 billion range. These technologies have rapidly moved from being a niche interest to becoming a mainstay in various business functions, attracting attention across industries and regions.

Notably, one-third of organizations are already using generative AI regularly, with a significant number of executives personally engaging with these tools for their work. This trend indicates a shift towards AI becoming a central focus for both tech specialists and company leaders.

Despite the fast-paced advancements, many companies are not fully prepared for the widespread use of generative AI or the business risks it may bring. This includes challenges in addressing inaccuracies, cybersecurity, and regulatory compliance. This situation highlights the urgency for organizations to develop robust frameworks for managing AI-related risks and adapting to an evolving regulatory landscape​​.

### The Rise of Open Source Models
Meta Platforms, in line with its commitment to open science, has taken significant steps to promote open-source AI models, including releasing large language models. In July 2023, Meta released a commercial version of its open-source artificial intelligence model Llama, named Llama 2. This model, previously available only to select academics, is now offered free-of-charge to start-ups and businesses, posing a significant challenge to the proprietary models sold by OpenAI and Google. Meta's approach to promoting open-source AI models aligns with its broader business strategy. Unlike companies primarily selling cloud computing services and proprietary software infrastructure, Meta, as a social media company, benefits more from standardizing the industry on the basic tools it uses. This strategy allows Meta to leverage crowd-sourced advancements, bug fixes, and products developed using its models, reducing infrastructure costs and creating new consumer-facing tools that support its ad-supported services.

Recent developments in open source AI models, particularly Mistral, have been influenced significantly by investments from major tech players and high-profile investors. Mistral, along with Hugging Face, is backed by Nvidia, Salesforce, and former Google CEO Eric Schmidt. This support is part of a broader trend where tech giants and investors are increasingly focusing on open source AI startups. The backing of these models by influential figures like Eric Schmidt points to a growing interest in and the potential of open-source solutions in the AI space. This shift is partly driven by the recent challenges and debates surrounding proprietary AI services, such as those by OpenAI, highlighting the need for diverse and open AI development platforms. The support from these investors is expected to bolster the expansion of open source AI initiatives, offering a counterpoint to the dominance of closed, proprietary AI models.

### Forecasts about the Future
The AI industry is anticipating bringing newly digital knowledge workers in the form of autonomous AI, and the substantial business disruptions due to generative AI, organizations are predicting significant changes to their workforces, including cuts in certain areas and large reskilling efforts to address evolving talent needs​​.
    https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2023-generative-AIs-breakout-year)

The popularity of generative AI tools, like Dall-E, Stable Diffusion, and ChatGPT, is set to continue, with expectations high for their impact on industry competition and operations​​.


## AI Safety and Responsible AI
The global adoption of AI has been accompanied by a patchwork of responses and regulatory approaches. Early in 2023, a law targeting AI bias came into effect in New York, reflecting a growing concern over the ethical implications of AI and its applications in sensitive areas such as hiring​​.
    https://www.techtarget.com/searchenterpriseai/feature/Four-AI-trends-to-look-for-in-2023#:~:text=The%20AI%20landscape%20changes%20daily%2C,trends%20in%20the%20upcoming%20year

### U.S. President Biden's Executive Order
On October 30, 2023, the US Executive Order on AI was released, days before the UK's Global AI Safety Summit.  The US announced AI Safety Institute and guidelines of government procurement of AI technologies. 

### The U.K. AI Safety Summit
The AI Safety Summit 2023, held at Bletchley Park, Buckinghamshire, was a significant global event, bringing together international governments, leading AI companies, civil society groups, and research experts. The summit focused on assessing the risks of AI, particularly at the frontier of development, and on fostering internationally coordinated action to mitigate these risks. The outcome included the Bletchley Declaration, a joint agreement aimed at the safe development of frontier AI​​​​. Furthermore, top AI firms outlined their safety policies, promoting transparency and best practices within the AI community​​.
    https://www.gov.uk/government/topical-events/ai-safety-summit-2023#:~:text=,safe%20development%20of%20Frontier%20AI

### E.U. AI Act
In recent weeks, key EU member states, including France, Germany, and Italy, have overcome significant disagreements regarding the EU's proposed AI Act, reaching a joint agreement expected to accelerate negotiations at the European level. Previously, the stance of these countries against certain regulations threatened to derail the legislation's progress in the European Parliament. Their agreement supports voluntary yet binding commitments on both small and large AI providers within the EU. The proposed approach emphasizes the need for conduct and transparency rules to apply universally, without initially imposing sanctions but allowing for their future establishment if code of conduct violations are identified. A European authority is anticipated to oversee compliance with these standards, focusing on regulating AI applications rather than the technology itself​​​.
- https://www.euronews.com/next/2023/11/19/eu-ai-act-germany-france-and-italy-reach-agreement-on-the-future-of-ai-regulation-in-europ

### U.S. Department of State Enterprise AI Strategy ("EAIS")
 The Department of State will responsibly and securely harness the full capabilities of trustworthy artificial intelligence to advance United States diplomacy and shape the future of statecraft.
The EAIS was releasd on November 23, 2023 with 4 goals:
- 1. Leverage Secure AI Infrastructure : Integrate AI technologies into a sustainable and secure AI-enabling infrastructure to build and scale a variety of AI applications across the Department.
- 2. Foster a Culture the Embraces AI Technology: Empower a dynamic workforce whose diverse needs for AI are served through training, a culture of continuous learning, and hiring for in-demand AI skills in ways that uphold the highest levels of data and scientific integrity.
- 3. Ensure AI is Applied Responsibly: Establish the enterprise capacity to ensure trustworthy and ethical AI use, manage algorithmic risk, and assess data quality while providing appropriate access to AI-ready data to inform decision-making and operations.
- 4. Innovate: Identify, experiment, and scale a range of successful solutions to be an active innovator in applied AI, while forming creative partnerships with responsible innovators outside of the Department to compound our successes.

### Industry Reactions and Adaptions
Well known platforms such as YouTube outline their approaches to responsible AI: “We’ll introduce updates that inform viewers when the content they’re seeing is synthetic.”
    https://blog.youtube/inside-youtube/our-approach-to-responsible-ai-innovation/



<br />* * * <br />

### Setting the Stage for 'Agentware', a New Form of Computing Set to Send Shock Waves Throughout the Software Industry  

In this dynamic and rapidly evolving world of AI, the fictional story of '***Agentware***' unfolds from today onwards througout the decade to 2030. *Agentware* isn't a category of software yet, but there's a very good chance it could be. The major platforms and many startups refer to "agents" as digital assistants that will accomplish specific tasks for us, such as reading our email and generating responses, booking our calendars, rebooking our flights, and more... because they will know us, our preferences and our objectives.  They'll effectively be making decisions on our behalf, like an athlete's agent or a real estate agent, for our benefit. 

In some cases, experts refer to digital agents as being "objective-driven", such that they can create a set of tasks to achieve an objective and then proceed to execute them. In today's terms, ChatGPTs code interpreter can both write code to achieve a task and then immediately go ahead and execute it our behalf.  

Based on interviews and research of the current day's technology innovations and the well-meaning intentions of AI Safety, "guardrail", and "containment" advocates and solution providers, we have a credible narrative of our global adoption of these technologies and their impacts on business and society.

We're already seeing prototypes of one agent generating some content and another agent checking that content.

The challenges are playing out in real time, even in 2023. There's not much debate as to whether AI technologies can help humanity solve the climate change crisis and improve our health and wellness by combating cancers. Governments, capital allocators and innovators are at odds about the impacts of LLMS in open source and closed source forms. 

In Agentware, our protagonist Ana, joins MarketSphere and finds herself at the intersection of groundbreaking AI innovations and the pressing need for ethical and safety considerations in AI development and application. Balancing innovation and safety is a new challenge for Ana and her team. She runs up against problems that threaten her company.  This backdrop sets the tone for the story, exploring the complexities of integrating AI into business and society, as experienced through the lens of Ana and her team.

<br /><br />
<hr />
<br/>

Next: Part I: The Awakening. <a href="https://github.com/alanwunsche/agentware-book/blob/main/Chapter-1/Chapter-1.md">Chapter 1: Unveiling Possibilities</a>

<br /><hr /><br />

### Contribute and Comment:

<a href="https://cal.com/alanwunsche">https://cal.com/alanwunsche</a> | <a href="https://x.com/alanwunsche">DM @alanwunsche</a> | <a href="https://linkedin.com/in/alanwunsche">DM on Linkedin</a>
<br /><br />
